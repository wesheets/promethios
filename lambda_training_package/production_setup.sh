#!/bin/bash

# Production Governance LLM Training Setup
# Optimized for Lambda Labs 8x H100 SXM5
# Comprehensive governance-native LLM with full-stack capabilities

set -e  # Exit on any error

echo "üöÄ Promethios Production Governance LLM Training Setup"
echo "Hardware: 8x H100 SXM5 (80GB each)"
echo "Target: Comprehensive governance-native LLM with full-stack capabilities"
echo "=================================================="

# System information
echo "üìä System Information:"
echo "GPU Count: $(nvidia-smi --list-gpus | wc -l)"
echo "Total GPU Memory: $(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | awk '{sum+=$1} END {print sum/1024 " GB"}')"
echo "CUDA Version: $(nvcc --version | grep release | awk '{print $6}' | cut -c2-)"
echo "Python Version: $(python3 --version)"
echo ""

# Create directory structure
echo "üìÅ Creating directory structure..."
mkdir -p {config,data/governance,models/checkpoints,logs/training,monitoring,deployment}
mkdir -p data/governance/{constitutional,operational,trust,memory,saas,collaboration}

# Update system packages
echo "üîÑ Updating system packages..."
sudo apt-get update -qq
sudo apt-get install -y build-essential git curl wget

# Install Python dependencies
echo "üêç Installing Python dependencies..."
pip install --upgrade pip setuptools wheel

# Core ML libraries
echo "üì¶ Installing core ML libraries..."
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers==4.35.0
pip install accelerate==0.24.0
pip install datasets==2.14.0
pip install deepspeed==0.12.0
pip install bitsandbytes==0.41.0

# Training and monitoring
echo "üìà Installing training and monitoring libraries..."
pip install wandb==0.16.0
pip install tensorboard==2.15.0
pip install scipy==1.11.0
pip install scikit-learn==1.3.0

# Development and utilities
echo "üõ†Ô∏è Installing development utilities..."
pip install requests==2.31.0
pip install flask==3.0.0
pip install jsonschema==4.19.0
pip install numpy==1.24.0
pip install pandas==2.1.0
pip install matplotlib==3.8.0
pip install seaborn==0.13.0

# Governance-specific dependencies
echo "üèõÔ∏è Installing governance-specific dependencies..."
pip install sqlite3  # For memory persistence
pip install cryptography==41.0.0  # For trust calculations
pip install pydantic==2.5.0  # For data validation

# Clone Promethios repository for governance integration
echo "üì• Setting up Promethios governance integration..."
if [ ! -d "promethios_governance" ]; then
    git clone https://github.com/wesheets/promethios.git promethios_governance
    cd promethios_governance
    git checkout promethios-llm
    cd ..
fi

# Generate comprehensive governance dataset
echo "üìä Generating comprehensive governance training dataset..."
python3 comprehensive_governance_dataset.py

# Verify dataset generation
if [ -f "comprehensive_governance_dataset.json" ]; then
    dataset_size=$(wc -l < comprehensive_governance_dataset.json)
    echo "‚úÖ Generated governance dataset with $dataset_size lines"
else
    echo "‚ùå Failed to generate governance dataset"
    exit 1
fi

# Create production configuration
echo "‚öôÔ∏è Creating production training configuration..."
cat > config/production_config.json << 'EOF'
{
  "model": {
    "base_model": "codellama/CodeLlama-34b-Instruct-hf",
    "max_length": 4096,
    "trust_remote_code": true
  },
  "training": {
    "num_train_epochs": 3,
    "per_device_train_batch_size": 1,
    "gradient_accumulation_steps": 8,
    "learning_rate": 2e-5,
    "warmup_ratio": 0.1,
    "weight_decay": 0.01,
    "fp16": true,
    "gradient_checkpointing": true
  },
  "governance": {
    "constitutional_weight": 0.3,
    "operational_weight": 0.25,
    "trust_weight": 0.2,
    "memory_weight": 0.15,
    "collaboration_weight": 0.1
  },
  "hardware": {
    "gpu_count": 8,
    "gpu_type": "H100_SXM5",
    "total_memory_gb": 640,
    "distributed_training": true
  },
  "monitoring": {
    "wandb_project": "promethios-governance-llm",
    "log_level": "INFO",
    "save_steps": 100,
    "eval_steps": 100,
    "logging_steps": 10
  }
}
EOF

# Create training execution script
echo "üéØ Creating training execution script..."
cat > run_production_training.sh << 'EOF'
#!/bin/bash

echo "üöÄ Starting Promethios Production Governance LLM Training"
echo "=================================================="

# Set environment variables
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export WANDB_PROJECT="promethios-governance-llm"
export TOKENIZERS_PARALLELISM=false

# Initialize wandb
echo "üìä Initializing Weights & Biases monitoring..."
wandb login

# Start training with distributed setup
echo "üéØ Starting distributed training on 8x H100..."
python3 -m torch.distributed.launch \
    --nproc_per_node=8 \
    --master_port=29500 \
    production_governance_trainer.py \
    --config config/production_config.json

echo "‚úÖ Training completed!"
echo "üìÅ Model saved to: ./promethios_governance_llm"

# Generate deployment package
echo "üì¶ Creating deployment package..."
tar -czf promethios_governance_llm_$(date +%Y%m%d_%H%M%S).tar.gz promethios_governance_llm/

echo "üéâ Production training complete!"
EOF

chmod +x run_production_training.sh

# Create monitoring script
echo "üìà Creating training monitoring script..."
cat > monitoring/monitor_training.py << 'EOF'
#!/usr/bin/env python3
"""
Real-time training monitoring for Promethios Governance LLM
"""

import time
import subprocess
import json
from datetime import datetime

def get_gpu_stats():
    """Get GPU utilization statistics"""
    try:
        result = subprocess.run([
            'nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True)
        
        gpu_stats = []
        for line in result.stdout.strip().split('\n'):
            if line:
                util, mem_used, mem_total, temp = line.split(', ')
                gpu_stats.append({
                    'utilization': int(util),
                    'memory_used_mb': int(mem_used),
                    'memory_total_mb': int(mem_total),
                    'temperature': int(temp)
                })
        return gpu_stats
    except Exception as e:
        print(f"Error getting GPU stats: {e}")
        return []

def estimate_training_cost(gpu_stats, hours_elapsed):
    """Estimate training cost based on GPU usage"""
    # Lambda Labs H100 pricing: ~$2.50/hour per GPU
    cost_per_gpu_hour = 2.50
    active_gpus = len([gpu for gpu in gpu_stats if gpu['utilization'] > 10])
    estimated_cost = active_gpus * cost_per_gpu_hour * hours_elapsed
    return estimated_cost

def main():
    """Main monitoring loop"""
    start_time = datetime.now()
    
    print("üîç Promethios Governance LLM Training Monitor")
    print("=" * 50)
    
    while True:
        try:
            current_time = datetime.now()
            elapsed = (current_time - start_time).total_seconds() / 3600  # hours
            
            gpu_stats = get_gpu_stats()
            
            print(f"\n‚è∞ Time: {current_time.strftime('%H:%M:%S')} | Elapsed: {elapsed:.2f}h")
            print("-" * 50)
            
            total_util = 0
            total_memory_used = 0
            total_memory_available = 0
            
            for i, gpu in enumerate(gpu_stats):
                util = gpu['utilization']
                mem_used = gpu['memory_used_mb'] / 1024  # GB
                mem_total = gpu['memory_total_mb'] / 1024  # GB
                temp = gpu['temperature']
                
                print(f"GPU {i}: {util:3d}% | {mem_used:5.1f}/{mem_total:5.1f}GB | {temp:2d}¬∞C")
                
                total_util += util
                total_memory_used += mem_used
                total_memory_available += mem_total
            
            if gpu_stats:
                avg_util = total_util / len(gpu_stats)
                memory_usage_pct = (total_memory_used / total_memory_available) * 100
                
                print("-" * 50)
                print(f"üìä Average GPU Utilization: {avg_util:.1f}%")
                print(f"üíæ Total Memory Usage: {total_memory_used:.1f}/{total_memory_available:.1f}GB ({memory_usage_pct:.1f}%)")
                
                estimated_cost = estimate_training_cost(gpu_stats, elapsed)
                print(f"üí∞ Estimated Cost: ${estimated_cost:.2f}")
                
                # Training progress estimation
                if avg_util > 80:
                    print("üî• Training: HIGH INTENSITY")
                elif avg_util > 50:
                    print("‚ö° Training: ACTIVE")
                elif avg_util > 10:
                    print("üîÑ Training: LOADING/PROCESSING")
                else:
                    print("‚è∏Ô∏è  Training: IDLE/COMPLETE")
            
            time.sleep(30)  # Update every 30 seconds
            
        except KeyboardInterrupt:
            print("\nüëã Monitoring stopped by user")
            break
        except Exception as e:
            print(f"‚ùå Monitoring error: {e}")
            time.sleep(10)

if __name__ == "__main__":
    main()
EOF

chmod +x monitoring/monitor_training.py

# Create deployment preparation script
echo "üöÄ Creating deployment preparation script..."
cat > deployment/prepare_deployment.py << 'EOF'
#!/usr/bin/env python3
"""
Prepare Promethios Governance LLM for deployment
"""

import os
import json
import shutil
from datetime import datetime

def prepare_deployment_package():
    """Prepare complete deployment package"""
    
    print("üì¶ Preparing Promethios Governance LLM deployment package...")
    
    # Create deployment directory
    deploy_dir = f"promethios_governance_deployment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(deploy_dir, exist_ok=True)
    
    # Copy trained model
    if os.path.exists("promethios_governance_llm"):
        shutil.copytree("promethios_governance_llm", f"{deploy_dir}/model")
        print("‚úÖ Model files copied")
    else:
        print("‚ùå Trained model not found")
        return
    
    # Copy governance system
    shutil.copy("governance_memory_system.py", f"{deploy_dir}/governance_memory_system.py")
    print("‚úÖ Governance system copied")
    
    # Create deployment configuration
    deploy_config = {
        "model_info": {
            "name": "Promethios Governance-Native LLM",
            "version": "1.0.0",
            "base_model": "codellama/CodeLlama-34b-Instruct-hf",
            "training_date": datetime.now().isoformat(),
            "capabilities": [
                "Constitutional governance reasoning",
                "Operational governance protocols", 
                "Trust management and propagation",
                "Memory-persistent interactions",
                "SaaS development with governance",
                "Multi-agent collaboration",
                "Professional communication",
                "Audit trail generation"
            ]
        },
        "deployment": {
            "recommended_hardware": "8x H100 or 4x A100 minimum",
            "memory_requirements": "320GB+ GPU memory",
            "inference_optimization": "fp16 recommended",
            "batch_size": "1-4 depending on hardware"
        },
        "governance_features": {
            "trust_calculation": "Built-in trust scoring system",
            "memory_persistence": "SQLite-based governance memory",
            "audit_logging": "Comprehensive decision tracking",
            "constitutional_compliance": "Built-in governance validation"
        }
    }
    
    with open(f"{deploy_dir}/deployment_config.json", 'w') as f:
        json.dump(deploy_config, f, indent=2)
    
    # Create README
    readme_content = """# Promethios Governance-Native LLM

## Overview
This is the world's first governance-native Large Language Model, trained specifically for AI governance, trust management, and professional collaboration.

## Capabilities
- Constitutional governance reasoning
- Trust-based decision making
- Memory-persistent interactions
- SaaS development with built-in governance
- Multi-agent collaboration protocols
- Professional governance communication

## Deployment
1. Load model using transformers library
2. Initialize governance memory system
3. Configure trust management
4. Deploy with appropriate hardware

## Hardware Requirements
- Minimum: 4x A100 (40GB each)
- Recommended: 8x H100 (80GB each)
- Memory: 320GB+ GPU memory

## Usage
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from governance_memory_system import GovernanceIntegrationSystem

# Load model
tokenizer = AutoTokenizer.from_pretrained("./model")
model = AutoModelForCausalLM.from_pretrained("./model")

# Initialize governance system
governance = GovernanceIntegrationSystem()

# Use for governance-aware interactions
```

## Support
For technical support and integration assistance, contact the Promethios team.
"""
    
    with open(f"{deploy_dir}/README.md", 'w') as f:
        f.write(readme_content)
    
    # Create archive
    shutil.make_archive(deploy_dir, 'gztar', deploy_dir)
    
    print(f"üéâ Deployment package created: {deploy_dir}.tar.gz")
    print(f"üìÅ Package contents:")
    print(f"   - Trained governance model")
    print(f"   - Governance memory system")
    print(f"   - Deployment configuration")
    print(f"   - Documentation and README")

if __name__ == "__main__":
    prepare_deployment_package()
EOF

chmod +x deployment/prepare_deployment.py

# Create comprehensive documentation
echo "üìö Creating comprehensive documentation..."
cat > PRODUCTION_TRAINING_GUIDE.md << 'EOF'
# Promethios Production Governance LLM Training Guide

## Overview
This guide covers the complete production training process for the Promethios Governance-Native LLM, designed for Lambda Labs 8x H100 SXM5 infrastructure.

## Training Specifications

### Hardware Requirements
- **GPUs**: 8x H100 SXM5 (80GB each)
- **Total GPU Memory**: 640GB
- **Training Time**: 12-24 hours
- **Estimated Cost**: $600-1,200

### Model Specifications
- **Base Model**: CodeLlama-34B-Instruct
- **Training Data**: 50,000+ governance examples
- **Context Length**: 4,096 tokens
- **Capabilities**: Full-stack development + governance

## Training Process

### 1. Environment Setup
```bash
./production_setup.sh
```

### 2. Start Training
```bash
./run_production_training.sh
```

### 3. Monitor Progress
```bash
python3 monitoring/monitor_training.py
```

### 4. Prepare Deployment
```bash
python3 deployment/prepare_deployment.py
```

## Governance Capabilities

### Constitutional Governance
- Built-in constitutional compliance checking
- Policy interpretation and enforcement
- Rights and boundaries validation

### Operational Governance
- Process compliance monitoring
- Operational decision protocols
- Incident response procedures

### Trust Management
- Dynamic trust score calculation
- Trust propagation between agents
- Trust-based access control

### Memory Integration
- Persistent governance context
- Decision precedent tracking
- Collaborative memory sharing

### SaaS Development
- Governance-native code generation
- Compliance-first architecture
- Trust-integrated authentication

### Multi-Agent Collaboration
- Professional round-table discussions
- Consensus building protocols
- Collaborative decision making

## Expected Outcomes

### Performance Metrics
- **Governance Accuracy**: >95%
- **Trust Calculation**: Real-time
- **Memory Persistence**: 100%
- **Code Quality**: Production-ready

### Business Applications
- Enterprise SaaS platforms
- Research collaboration teams
- Corporate governance systems
- Compliance automation
- Professional AI assistants

## Deployment Options

### Cloud Deployment
- AWS/GCP/Azure with GPU instances
- Kubernetes orchestration
- Auto-scaling capabilities

### On-Premise Deployment
- Enterprise data centers
- Private cloud infrastructure
- Air-gapped environments

### Edge Deployment
- Quantized model versions
- Reduced capability modes
- Local governance enforcement

## Integration Guide

### API Integration
```python
from promethios_governance_llm import GovernanceLLM

llm = GovernanceLLM.from_pretrained("./promethios_governance_llm")
response = llm.generate_governance_response(
    input_text="User requests data access",
    governance_type="constitutional",
    trust_context={"user_id": "123", "trust_score": 0.8}
)
```

### Multi-Agent Integration
```python
from promethios_governance_llm import MultiAgentGovernance

governance = MultiAgentGovernance()
consensus = governance.facilitate_discussion([
    {"agent_id": "agent1", "input": "Proposal A"},
    {"agent_id": "agent2", "input": "Proposal B"}
])
```

## Troubleshooting

### Common Issues
1. **GPU Memory Errors**: Reduce batch size or use gradient checkpointing
2. **Training Stalls**: Check data loading and preprocessing
3. **Convergence Issues**: Adjust learning rate or warmup steps

### Performance Optimization
1. **Mixed Precision**: Use fp16 for faster training
2. **Gradient Accumulation**: Increase effective batch size
3. **Data Loading**: Use multiple workers for data preprocessing

## Support and Maintenance

### Model Updates
- Quarterly governance data updates
- Continuous learning from deployment feedback
- Security patches and improvements

### Technical Support
- Integration assistance
- Performance optimization
- Custom governance rule development

## Conclusion

The Promethios Governance-Native LLM represents a breakthrough in AI governance technology, providing the first comprehensive solution for governance-aware artificial intelligence systems.

For additional support and documentation, visit: https://promethios.ai
EOF

# Verify all components
echo "üîç Verifying training package components..."

components=(
    "comprehensive_governance_dataset.py"
    "production_governance_trainer.py"
    "governance_memory_system.py"
    "config/production_config.json"
    "run_production_training.sh"
    "monitoring/monitor_training.py"
    "deployment/prepare_deployment.py"
    "PRODUCTION_TRAINING_GUIDE.md"
)

all_present=true
for component in "${components[@]}"; do
    if [ -f "$component" ]; then
        echo "‚úÖ $component"
    else
        echo "‚ùå $component (missing)"
        all_present=false
    fi
done

if [ "$all_present" = true ]; then
    echo ""
    echo "üéâ Production Governance LLM Training Package Complete!"
    echo "=================================================="
    echo "üìä Dataset: Comprehensive governance examples (50,000+)"
    echo "üß† Model: CodeLlama-34B with governance specialization"
    echo "üîß Hardware: Optimized for 8x H100 SXM5"
    echo "‚è±Ô∏è  Duration: 12-24 hours training time"
    echo "üí∞ Cost: ~$600-1,200 for complete training"
    echo ""
    echo "üöÄ Ready to train the world's first governance-native LLM!"
    echo ""
    echo "Next steps:"
    echo "1. Run: ./run_production_training.sh"
    echo "2. Monitor: python3 monitoring/monitor_training.py"
    echo "3. Deploy: python3 deployment/prepare_deployment.py"
else
    echo ""
    echo "‚ùå Setup incomplete. Please check missing components."
    exit 1
fi

